{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ff5267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.linalg import orth\n",
    "np.random.seed(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5e69f9-4c2f-4260-903e-05a774e93694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_action_set(trials, M_list, epochs, num_target_sample, M, d, nu_list, N_i):\n",
    "    \n",
    "    source_data_list = []\n",
    "    target_data_list = []\n",
    "    \n",
    "    B_star_list = []\n",
    "    W_star_list = []\n",
    "    Theta_star_list = []\n",
    "    W_target_star_list = []\n",
    "    Theta_target_star_list = []\n",
    "    \n",
    "    for M_index, M in enumerate(M_list):\n",
    "        \n",
    "        source_data = np.random.randn(epochs, trials, M, N_i, d)\n",
    "        target_data = np.random.randn(epochs, trials, num_target_sample, d)\n",
    "        \n",
    "        source_data_list.append(source_data)\n",
    "        target_data_list.append(target_data)\n",
    "        \n",
    "        B_star_temp = []\n",
    "        W_star_temp = []\n",
    "        Theta_star_temp = []\n",
    "        W_target_star_temp = []\n",
    "        Theta_target_star_temp = []\n",
    "        \n",
    "        for T in range(trials):\n",
    "            \n",
    "            B_star = orth(np.random.rand(d, k))\n",
    "            W_star = np.random.rand(k, M)\n",
    "            Theta_star = np.dot(B_star, W_star)\n",
    "            W_target_star = np.dot(W_star, nu_list[M_index])\n",
    "            Theta_target_star = B_star.dot(W_target_star)\n",
    "            \n",
    "            B_star_temp.append(B_star)\n",
    "            W_star_temp.append(W_star)\n",
    "            Theta_star_temp.append(Theta_star)\n",
    "            W_target_star_temp.append(W_target_star)\n",
    "            Theta_target_star_temp.append(Theta_target_star)\n",
    "            \n",
    "        B_star_list.append(B_star_temp)\n",
    "        W_star_list.append(W_star_temp)\n",
    "        Theta_star_list.append(Theta_star_temp)\n",
    "        W_target_star_list.append(W_target_star_temp)\n",
    "        Theta_target_star_list.append(Theta_target_star_temp)\n",
    "        \n",
    "    return source_data_list, target_data_list, B_star_list, W_star_list, Theta_star_list, W_target_star_list, Theta_target_star_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26059256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nu(M):\n",
    "    \n",
    "    nu = np.zeros(M)\n",
    "    \n",
    "    nu[:int(0.2 * M)] = 2\n",
    "    nu[int(0.2 * M) : int(0.8 * M)] = 6\n",
    "    nu[int(0.8 * M):] = 10\n",
    "    \n",
    "    np.random.shuffle(nu)\n",
    "    nu = nu / np.sum(nu)\n",
    "    \n",
    "    return nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e6964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_altgdmin_1(X, Y, C, M, d, k):\n",
    "    \n",
    "    alpha = C * np.sum([np.sum(y ** 2) / len(y) for y in Y]) / M\n",
    "    \n",
    "    Y_trunc = np.copy(Y)\n",
    "    Y_trunc[np.abs(Y) > alpha] = 0\n",
    "    \n",
    "    Theta_0 = np.zeros((d, M))\n",
    "    \n",
    "    for i in range(M):\n",
    "        \n",
    "        Theta_0[:, i] = np.sum(X[i].dot(np.diag(Y_trunc[i])), axis=1)\n",
    "    \n",
    "    U_0, Sigma_0, V_0 = np.linalg.svd(Theta_0, full_matrices=False)\n",
    "    U_0 = U_0[:, :k]\n",
    "    Sigma_0 = Sigma_0[:k]\n",
    "    \n",
    "    return U_0, np.max(Sigma_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870932a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AltGD_Min_1(X, Y, C, M, d, k, Theta_star, U_star, gd_iterations):\n",
    "    \n",
    "    U_init, Sigma_max = init_altgdmin_1(X, Y, C, M, d, k)\n",
    "    U_hat = np.copy(U_init)\n",
    "    \n",
    "    B_hat = np.zeros((k, M))\n",
    "    eta = 1 / Sigma_max\n",
    "    \n",
    "    error_list = []\n",
    "    error = np.linalg.norm(U_star - U_hat, 'fro') / np.linalg.norm(U_star, 'fro')\n",
    "    error_list.append(error)\n",
    "    \n",
    "    for num in range(gd_iterations):\n",
    "        \n",
    "        for i in range(M):\n",
    "            \n",
    "            B_hat[:, i] = np.linalg.pinv(np.dot(X[i].T, U_hat)).dot(Y[i])\n",
    "            \n",
    "        Theta_hat = np.dot(U_hat, B_hat)\n",
    "        U_grad = np.zeros((d, k))\n",
    "        \n",
    "        for i in range(M):\n",
    "            \n",
    "            U_grad += X[i] @ (X[i].T @ Theta_hat[:, i].reshape(-1, 1) - Y[i].reshape(-1, 1)) @ B_hat[:, i].reshape(1, -1) / X[i].shape[-1]\n",
    "            \n",
    "        U_hat = U_hat - eta * U_grad\n",
    "        q, r = np.linalg.qr(U_hat)\n",
    "        U_hat = q[:, :k]\n",
    "        \n",
    "        Theta_hat_ = np.dot(U_hat, B_hat)\n",
    "        error = np.linalg.norm(Theta_star - Theta_hat_, 'fro') / np.linalg.norm(Theta_star, 'fro')\n",
    "        error_list.append(error)\n",
    "        \n",
    "    return U_hat, B_hat, eta, error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d1b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AltGD_Min_2(X, Y, M, d, k, B_hat, eta, gd_iterations):\n",
    "    \n",
    "    U_hat = np.copy(B_hat)\n",
    "    \n",
    "    B_hat = np.zeros((k, M))\n",
    "    \n",
    "    for num in range(gd_iterations):\n",
    "        \n",
    "        for i in range(M):\n",
    "            \n",
    "            B_hat[:, i] = np.linalg.pinv(np.dot(X[i].T, U_hat)).dot(Y[i])\n",
    "            \n",
    "        Theta_hat = np.dot(U_hat, B_hat)\n",
    "            \n",
    "        U_grad = np.zeros((d, k))\n",
    "        \n",
    "        for i in range(M):\n",
    "            \n",
    "            U_grad += X[i] @ (X[i].T @ Theta_hat[:, i].reshape(-1, 1) - Y[i].reshape(-1, 1)) @ B_hat[:, i].reshape(1, -1) / X[i].shape[-1]\n",
    "            \n",
    "        U_hat = U_hat - eta * U_grad\n",
    "        q, r = np.linalg.qr(U_hat)\n",
    "        U_hat = q[:, :k]\n",
    "        \n",
    "    return U_hat, B_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b34407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd_Theta(X, Y, M, gd_iteration, learning_rate, Theta_star):\n",
    "    \n",
    "    def compute_loss_grad(X, Y, Theta, M):\n",
    "        \n",
    "        loss = 0\n",
    "        grad = np.zeros_like(Theta)\n",
    "        \n",
    "        for m in range(M):\n",
    "            \n",
    "            error_list = X[m].T.dot(Theta[:, m]) - Y[m]\n",
    "            loss += 0.5 * np.sum(error_list ** 2)\n",
    "            grad[:, m] = X[m].dot(error_list)\n",
    "            \n",
    "        nuclear_norm = np.sum(np.linalg.svd(Theta, compute_uv=False))\n",
    "        loss += nuclear_norm\n",
    "        \n",
    "        U, _, Vt = np.linalg.svd(Theta, full_matrices=False)\n",
    "        nuclear_grad = np.dot(U, Vt)\n",
    "        grad += nuclear_grad\n",
    "            \n",
    "        return loss, grad\n",
    "    \n",
    "    Theta = np.ones((d, M))\n",
    "    error_list = []\n",
    "    \n",
    "    error = np.linalg.norm(Theta_star - Theta, 'fro') / np.linalg.norm(Theta_star, 'fro')\n",
    "    error_list.append(error)\n",
    "    \n",
    "    for i in range(gd_iteration):\n",
    "        \n",
    "        loss, grad = compute_loss_grad(X, Y, Theta, M)\n",
    "        Theta -= learning_rate * grad\n",
    "        \n",
    "        error = np.linalg.norm(Theta_star - Theta, 'fro') / np.linalg.norm(Theta_star, 'fro')\n",
    "        error_list.append(error)\n",
    "        \n",
    "    return Theta, error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ea9bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_altgdmin_2(X, Y, M, d, k):\n",
    "    \n",
    "    Z = np.zeros((d, d))\n",
    "    \n",
    "    for m in range(M):\n",
    "        \n",
    "        for n in range(X[m].shape[1]):\n",
    "            \n",
    "            Z += Y[m][n] ** 2 * np.dot(X[m][:, n][:, np.newaxis], X[m][:, n][:, np.newaxis].T)\n",
    "            \n",
    "        Z /= X[m].shape[1]\n",
    "        \n",
    "    Z /= m\n",
    "    \n",
    "    U_0, Sigma_0, V_0 = np.linalg.svd(Z, full_matrices=False)\n",
    "    U_0 = U_0[:, :k]\n",
    "    \n",
    "    return U_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d07680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AltGD_Min_Collins1(X, Y, M, d, k, Theta_star, U_star, gd_iterations):\n",
    "    \n",
    "    U_init = init_altgdmin_2(X, Y, M, d, k)\n",
    "    U_hat = np.copy(U_init)\n",
    "    B_hat = np.zeros((k, M))\n",
    "    \n",
    "    error_list = []\n",
    "    error = np.linalg.norm(U_star - U_hat, 'fro') / np.linalg.norm(U_star, 'fro')\n",
    "    error_list.append(error)\n",
    "    \n",
    "    for num in range(gd_iterations):\n",
    "        \n",
    "        M_sub_value = int(np.random.uniform(low = 1e-1, high = 1 + 1e-10) * M)\n",
    "        M_sub = np.random.choice(range(M), M_sub_value, replace = False)\n",
    "        \n",
    "        for i in M_sub:\n",
    "            \n",
    "            XB = X[i].T.dot(U_hat)\n",
    "            B_hat[:, i] = np.linalg.pinv(XB.T.dot(XB)).dot(XB.T).dot(Y[i])\n",
    "            \n",
    "        Theta_hat = np.dot(U_hat, B_hat)\n",
    "        U_grad = np.zeros((d, k))\n",
    "        \n",
    "        for i in M_sub:\n",
    "            \n",
    "            U_grad += X[i] @ (X[i].T @ Theta_hat[:, i].reshape(-1, 1) - Y[i].reshape(-1, 1)) @ B_hat[:, i].reshape(1, -1) / X[i].shape[-1]\n",
    "            \n",
    "        U_hat = U_hat - (1 / M_sub_value) * U_grad\n",
    "        # q, r = np.linalg.qr(U_hat)\n",
    "        # U_hat = q[:, :k]\n",
    "        \n",
    "        Theta_hat_ = np.dot(U_hat, B_hat)\n",
    "        error = np.linalg.norm(Theta_star - Theta_hat_, 'fro') / np.linalg.norm(Theta_star, 'fro')\n",
    "        error_list.append(error)\n",
    "        \n",
    "    return U_hat, B_hat, error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615587ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AltGD_Min_Collins2(X, Y, M, d, k, B_hat, gd_iterations):\n",
    "    \n",
    "    U_hat = np.copy(B_hat)\n",
    "    \n",
    "    B_hat = np.zeros((k, M))\n",
    "    \n",
    "    for num in range(gd_iterations):\n",
    "        \n",
    "        M_sub_value = int(np.random.uniform(low = 1e-1, high = 1 + 1e-10) * M)\n",
    "        M_sub = np.random.choice(range(M), M_sub_value, replace = False)\n",
    "        \n",
    "        for i in M_sub:\n",
    "            \n",
    "            XB = X[i].T.dot(U_hat)\n",
    "            B_hat[:, i] = np.linalg.pinv(XB.T.dot(XB)).dot(XB.T).dot(Y[i])\n",
    "            \n",
    "        Theta_hat = np.dot(U_hat, B_hat)\n",
    "            \n",
    "        U_grad = np.zeros((d, k))\n",
    "        \n",
    "        for i in M_sub:\n",
    "            \n",
    "            U_grad += X[i] @ (X[i].T @ Theta_hat[:, i].reshape(-1, 1) - Y[i].reshape(-1, 1)) @ B_hat[:, i].reshape(1, -1) / X[i].shape[-1]\n",
    "            \n",
    "        U_hat = U_hat - (1 / M_sub_value) * U_grad\n",
    "        q, r = np.linalg.qr(U_hat)\n",
    "        U_hat = q[:, :k]\n",
    "        \n",
    "    return U_hat, B_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043664ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "C = [1.0, 1.2, 1.6]\n",
    "k = 2\n",
    "d = 100\n",
    "ld_0 = 1\n",
    "epochs = 4\n",
    "trials = 100\n",
    "delta = 1e-3\n",
    "noise_var = 1e-2\n",
    "learning_rate = 1e-3\n",
    "gd_iterations = [40, 40, 40]\n",
    "num_target_sample = 30\n",
    "M_list = [40, 60, 80]\n",
    "gd_iterations_chen = 50\n",
    "increase_gd_iteration = [10, 10, 10]\n",
    "ER_list1 = []\n",
    "ER_list2 = []\n",
    "ER_list3 = []\n",
    "ER_list4 = []\n",
    "ER_list5 = []\n",
    "gd_error_list1 = []\n",
    "gd_error_list3 = []\n",
    "gd_error_list4 = []\n",
    "gd_error_list5 = []\n",
    "percentage_error_list2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c863eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the nu\n",
    "nu_list = []\n",
    "\n",
    "for M_index, M in enumerate(M_list):\n",
    "    \n",
    "#     # method 1\n",
    "#     nu = np.random.rand(M)\n",
    "#     nu = np.power(nu, 3)\n",
    "#     nu /= np.sum(nu)\n",
    "    \n",
    "    # method 2\n",
    "    nu = generate_nu(M)\n",
    "    \n",
    "    nu_list.append(nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec86d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the total number of sample\n",
    "num_sample = 50\n",
    "N_i = num_sample * M\n",
    "N = N_i * epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae97720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the data\n",
    "source_data_list, target_data_list, B_star_list, W_star_list, Theta_star_list, W_target_star_list, Theta_target_star_list = generate_action_set(trials, M_list, epochs, num_target_sample, M, d, nu_list, N_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1829c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the noise\n",
    "noise = np.random.normal(0, noise_var, size = (trials, epochs, M + 1, N_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af1c00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# AltGDmin Algorithm\n",
    "start = time.time()\n",
    "\n",
    "for T in range(trials):\n",
    "    \n",
    "    print('Trial:', T)\n",
    "    \n",
    "    for index, M in enumerate(M_list):\n",
    "        \n",
    "        B_star = B_star_list[index]\n",
    "        W_star = W_star_list[index]\n",
    "        Theta_star = Theta_star_list[index]\n",
    "        W_target_star = W_target_star_list[index]\n",
    "        Theta_target_star = Theta_target_star_list[index]\n",
    "        \n",
    "        ER_1 = []\n",
    "        nu_hat = [1 / M for m in range(M)]\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            \n",
    "            source_data = source_data_list[index][i]\n",
    "            target_data = target_data_list[index][i]\n",
    "            \n",
    "            X = []\n",
    "            Y = []\n",
    "            \n",
    "            # new\n",
    "            index_m = []\n",
    "            \n",
    "            for m in range(M):\n",
    "                \n",
    "                n_m = int((N / epochs) * (np.abs(nu_hat) / np.linalg.norm(nu_hat, 1))[m])\n",
    "                \n",
    "                # new\n",
    "                if n_m == 0:\n",
    "                    \n",
    "                    M = M - 1\n",
    "                    index_m.append(m)\n",
    "                    \n",
    "                    continue\n",
    "                \n",
    "                X_temp = np.zeros((d, n_m))\n",
    "                Y_temp = np.zeros(n_m)\n",
    "                \n",
    "                for num in range(n_m):\n",
    "                    \n",
    "                    X_temp[:, num] = source_data[T][m][num]\n",
    "                    Y_temp[num] = source_data[T][m][num].dot(Theta_star[T][:, m]) + noise[T][i][m][num]\n",
    "                    \n",
    "                X.append(X_temp)\n",
    "                Y.append(Y_temp)\n",
    "                \n",
    "            # new\n",
    "            if len(index_m) > 0:\n",
    "                \n",
    "                W_hat_m = W_hat[:, index_m]\n",
    "                \n",
    "            if i == 0:\n",
    "                \n",
    "                B_hat, W_hat, eta, error_list1 = AltGD_Min_1(X, Y, C[index], M, d, k, Theta_star[T], B_star[T], gd_iterations[index])\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                B_hat, W_hat = AltGD_Min_2(X, Y, M, d, k, B_hat, eta, gd_iterations[index] + (i - 1) * increase_gd_iteration[index])\n",
    "                \n",
    "            # new\n",
    "            if len(index_m) > 0:\n",
    "                \n",
    "                j = 0\n",
    "                W_temp = np.zeros((k, M + len(index_m)))\n",
    "                \n",
    "                for v in range(M + len(index_m)):\n",
    "                    \n",
    "                    if v in index_m:\n",
    "                        \n",
    "                        continue\n",
    "                        \n",
    "                    W_temp[:, v] = W_hat[:, j]\n",
    "                    j += 1\n",
    "                    \n",
    "                for idx, column in zip(index_m, W_hat_m.T):\n",
    "                    \n",
    "                    W_temp[:, idx] = column\n",
    "                    \n",
    "                W_hat = W_temp\n",
    "                M = M_list[index]\n",
    "                \n",
    "            Theta_hat = B_hat.dot(W_hat)\n",
    "            error = np.linalg.norm(Theta_star[T] - Theta_hat, 'fro') / np.linalg.norm(Theta_star[T], 'fro')\n",
    "            \n",
    "            X_target = np.zeros((num_target_sample, d))\n",
    "            Y_target = np.zeros(num_target_sample)\n",
    "            \n",
    "            for num in range(num_target_sample):\n",
    "                \n",
    "                X_target[num, :] = target_data[T][num]\n",
    "                Y_target[num] = target_data[T][num].dot(Theta_target_star[T]) + noise[T][i][M][num]\n",
    "                \n",
    "            w_hat_target = np.linalg.pinv(X_target.dot(B_hat)).dot(Y_target)\n",
    "            nu_hat = W_hat.T.dot(np.linalg.pinv(np.dot(W_hat, W_hat.T))).dot(w_hat_target)\n",
    "            nu_error = np.linalg.norm(nu_hat - np.linalg.pinv(W_star[T]).dot(W_target_star[T])) / np.linalg.norm(nu)\n",
    "            \n",
    "            term1 = X_target.dot(B_hat).dot(w_hat_target)\n",
    "            term2 = X_target.dot(Theta_target_star[T])\n",
    "            ER = np.sum((term1 - term2) ** 2) / num_target_sample\n",
    "            \n",
    "            ER_1.append(ER)\n",
    "            # print('M: {} epoch: {} error: {} nu_error: {}:'.format(M, i, error, nu_error))\n",
    "            \n",
    "        ER_list1.append((T, M, ER_1))\n",
    "        gd_error_list1.append((T, M, error_list1))\n",
    "        \n",
    "end = time.time()\n",
    "print('Finished! The total time we use is: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f2ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOM Algorithm\n",
    "start = time.time()\n",
    "\n",
    "for T in range(trials):\n",
    "    \n",
    "    print('Trial:', T)\n",
    "    \n",
    "    for index, M in enumerate(M_list):\n",
    "        \n",
    "        B_star = B_star_list[index]\n",
    "        W_star = W_star_list[index]\n",
    "        Theta_star = Theta_star_list[index]\n",
    "        W_target_star = W_target_star_list[index]\n",
    "        Theta_target_star = Theta_target_star_list[index]\n",
    "        \n",
    "        ER_2 = []\n",
    "        percentage_error_2 = []\n",
    "        B_hat = np.zeros((d, k))\n",
    "        W_hat = np.zeros((k, M))\n",
    "        Theta_hat = B_hat.dot(W_hat)\n",
    "        \n",
    "        M_hat = np.zeros((d, d))\n",
    "        nu_hat = [1 / M for m in range(M)]\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            \n",
    "            source_data = source_data_list[index][i]\n",
    "            target_data = target_data_list[index][i]\n",
    "            \n",
    "            if i == 0:\n",
    "                \n",
    "                n_m_i = 0\n",
    "                \n",
    "                for m in range(M):\n",
    "                    \n",
    "                    n_m = int((N / epochs) * (np.abs(nu_hat) / np.linalg.norm(nu_hat, 1))[m])\n",
    "                    n_m_i += n_m\n",
    "                    \n",
    "                    for num in range(n_m):\n",
    "                        \n",
    "                        x_temp = source_data[T][m][num]\n",
    "                        y_temp = source_data[T][m][num].dot(Theta_star[T][:, m]) + noise[T][i][m][num]\n",
    "                        M_hat = M_hat + y_temp ** 2 * np.dot(x_temp.T, x_temp)\n",
    "                        \n",
    "                M_hat = (1 / n_m_i) * M_hat\n",
    "                \n",
    "                U, Sigma, V = np.linalg.svd(M_hat, full_matrices=False)\n",
    "                B_hat = U[:, :k]\n",
    "            \n",
    "                X_target = np.zeros((num_target_sample, d))\n",
    "                Y_target = np.zeros(num_target_sample)\n",
    "                \n",
    "                for num in range(num_target_sample):\n",
    "\n",
    "                    X_target[num, :] = target_data[T][num]\n",
    "                    Y_target[num] = target_data[T][num].dot(Theta_target_star[T]) + noise[T][i][M][num]\n",
    "                    \n",
    "                w_hat_target = np.linalg.pinv(X_target.dot(B_hat)).dot(Y_target)\n",
    "                \n",
    "                term1 = X_target.dot(B_hat).dot(w_hat_target)\n",
    "                term2 = X_target.dot(Theta_target_star[T])\n",
    "                ER = np.sum((term1 - term2) ** 2) / num_target_sample\n",
    "                ER_2.append(ER)\n",
    "                \n",
    "            elif i == 1:\n",
    "                \n",
    "                X = []\n",
    "                Y = []\n",
    "                \n",
    "                for m in range(M):\n",
    "                    \n",
    "                    n_m = int((N / epochs) * (np.abs(nu_hat) / np.linalg.norm(nu_hat, 1))[m])\n",
    "                    \n",
    "                    X_temp = np.zeros((d, int(n_m / k) * k))\n",
    "                    Y_temp = np.zeros(int(n_m / k) * k)\n",
    "                    \n",
    "                    for num in range(int(n_m / k)):\n",
    "                        \n",
    "                        for k_value in range(k):\n",
    "                            \n",
    "                            X_temp[:, num * k + k_value] = np.sqrt(ld_0) * B_hat[:, k_value]\n",
    "                            Y_temp[num * k + k_value] = X_temp[:, num * k + k_value].reshape(1, -1).dot(Theta_star[T][:, m]) + noise[T][i][m][num]\n",
    "                            \n",
    "                    X.append(X_temp)\n",
    "                    Y.append(Y_temp)\n",
    "                    \n",
    "                for m in range(M):\n",
    "                    \n",
    "                    temp = X[m].T.dot(B_hat)\n",
    "                    W_hat[:, m] = np.linalg.lstsq(temp, Y[m], rcond=None)[0]\n",
    "                    \n",
    "                Theta_hat = B_hat.dot(W_hat)\n",
    "                \n",
    "                error = np.linalg.norm(Theta_star[T] - Theta_hat, 'fro') / np.linalg.norm(Theta_star[T], 'fro')\n",
    "                \n",
    "                X_target = np.zeros((num_target_sample, d))\n",
    "                Y_target = np.zeros(num_target_sample)\n",
    "                \n",
    "                for num in range(num_target_sample):\n",
    "                    \n",
    "                    X_target[num, :] = target_data[T][num]\n",
    "                    Y_target[num] = target_data[T][num].dot(Theta_target_star[T]) + noise[T][i][M][num]\n",
    "                    \n",
    "                w_hat_target = np.linalg.pinv(X_target.dot(B_hat)).dot(Y_target)\n",
    "                nu_hat = W_hat.T.dot(np.linalg.pinv(np.dot(W_hat, W_hat.T))).dot(w_hat_target)\n",
    "                nu_error = np.linalg.norm(nu_hat - np.linalg.pinv(W_star[T]).dot(W_target_star[T])) / np.linalg.norm(nu)\n",
    "                \n",
    "                term1 = X_target.dot(B_hat).dot(w_hat_target)\n",
    "                term2 = X_target.dot(Theta_target_star[T])\n",
    "                ER = np.sum((term1 - term2) ** 2) / num_target_sample\n",
    "                \n",
    "                ER_2.append(ER)\n",
    "                percentage_error_2.append(error)\n",
    "                # print('M: {} epoch: {} error: {} nu_error: {}:'.format(M, i, error, nu_error))\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                X_target = np.zeros((num_target_sample, d))\n",
    "                Y_target = np.zeros(num_target_sample)\n",
    "                \n",
    "                for num in range(num_target_sample):\n",
    "                    \n",
    "                    X_target[num, :] = target_data[T][num]\n",
    "                    Y_target[num] = target_data[T][num].dot(Theta_target_star[T]) + noise[T][i][M][num]\n",
    "                    \n",
    "                w_hat_target = np.linalg.pinv(X_target.dot(B_hat)).dot(Y_target)\n",
    "                nu_hat = W_hat.T.dot(np.linalg.pinv(np.dot(W_hat, W_hat.T))).dot(w_hat_target)\n",
    "                nu_error = np.linalg.norm(nu_hat - np.linalg.pinv(W_star[T]).dot(W_target_star[T])) / np.linalg.norm(nu)\n",
    "                \n",
    "                term1 = X_target.dot(B_hat).dot(w_hat_target)\n",
    "                term2 = X_target.dot(Theta_target_star[T])\n",
    "                ER = np.sum((term1 - term2) ** 2) / num_target_sample\n",
    "                \n",
    "                ER_2.append(ER)\n",
    "                # print('M: {} epoch: {} error: {} nu_error: {}:'.format(M, i, error, nu_error))\n",
    "            \n",
    "        ER_list2.append((T, M, ER_2))\n",
    "        percentage_error_list2.append((T, M, percentage_error_2))\n",
    "        \n",
    "end = time.time()\n",
    "print('Finished! The total time we use is: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0129ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Chen et al. Algorithm\n",
    "start = time.time()\n",
    "\n",
    "for T in range(trials):\n",
    "    \n",
    "    print('Trial:', T)\n",
    "    \n",
    "    for index, M in enumerate(M_list):\n",
    "        \n",
    "        B_star = B_star_list[index]\n",
    "        W_star = W_star_list[index]\n",
    "        Theta_star = Theta_star_list[index]\n",
    "        W_target_star = W_target_star_list[index]\n",
    "        Theta_target_star = Theta_target_star_list[index]\n",
    "        \n",
    "        ER_3 = []\n",
    "        nu_hat = [1 / M for m in range(M)]\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            \n",
    "            source_data = source_data_list[index][i]\n",
    "            target_data = target_data_list[index][i]\n",
    "            \n",
    "            X = []\n",
    "            Y = []\n",
    "            \n",
    "            for m in range(M):\n",
    "                \n",
    "                n_m = int((N / epochs) * (np.abs(nu_hat) / np.linalg.norm(nu_hat, 1))[m])\n",
    "                \n",
    "                X_temp = np.zeros((d, n_m))\n",
    "                Y_temp = np.zeros(n_m)\n",
    "                \n",
    "                for num in range(n_m):\n",
    "                    \n",
    "                    X_temp[:, num] = source_data[T][m][num]\n",
    "                    Y_temp[num] = source_data[T][m][num].dot(Theta_star[T][:, m]) + noise[T][i][m][num]\n",
    "                    \n",
    "                X.append(X_temp)\n",
    "                Y.append(Y_temp)\n",
    "                \n",
    "            Theta_hat, error_list_chen = gd_Theta(X, Y, M, gd_iterations_chen, learning_rate, Theta_star[T])\n",
    "            B_hat, Sigma_hat, V_hat = np.linalg.svd(Theta_hat, full_matrices=False)\n",
    "            B_hat = B_hat[:, :k]\n",
    "            W_hat = np.diag(Sigma_hat[:k]).dot(V_hat[:k, :])\n",
    "            \n",
    "            error = np.linalg.norm(Theta_star[T] - Theta_hat, 'fro') / np.linalg.norm(Theta_star[T], 'fro')\n",
    "            \n",
    "            X_target = np.zeros((num_target_sample, d))\n",
    "            Y_target = np.zeros(num_target_sample)\n",
    "            \n",
    "            for num in range(num_target_sample):\n",
    "                \n",
    "                X_target[num, :] = target_data[T][num]\n",
    "                Y_target[num] = target_data[T][num].dot(Theta_target_star[T]) + noise[T][i][M][num]\n",
    "                \n",
    "            w_hat_target = np.linalg.pinv(X_target.dot(B_hat)).dot(Y_target)\n",
    "            nu_hat = W_hat.T.dot(np.linalg.pinv(np.dot(W_hat, W_hat.T))).dot(w_hat_target)\n",
    "            nu_error = np.linalg.norm(nu_hat - np.linalg.pinv(W_star[T]).dot(W_target_star[T])) / np.linalg.norm(nu)\n",
    "            \n",
    "            term1 = X_target.dot(B_hat).dot(w_hat_target)\n",
    "            term2 = X_target.dot(Theta_target_star[T])\n",
    "            ER = np.sum((term1 - term2) ** 2) / num_target_sample\n",
    "            \n",
    "            ER_3.append(ER)\n",
    "            # print('M: {} epoch: {} error: {} nu_error: {}:'.format(M, i, error, nu_error))aa'aa\n",
    "            \n",
    "        ER_list3.append((T, M, ER_3))\n",
    "        gd_error_list3.append((T, M, error_list_chen))\n",
    "        \n",
    "end = time.time()\n",
    "print('Finished! The total time we use is: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e26e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform Sampling\n",
    "start = time.time()\n",
    "\n",
    "for T in range(trials):\n",
    "    \n",
    "    print('Trial:', T)\n",
    "    \n",
    "    for index, M in enumerate(M_list):\n",
    "        \n",
    "        B_star = B_star_list[index]\n",
    "        W_star = W_star_list[index]\n",
    "        Theta_star = Theta_star_list[index]\n",
    "        W_target_star = W_target_star_list[index]\n",
    "        Theta_target_star = Theta_target_star_list[index]\n",
    "        \n",
    "        ER_4 = []\n",
    "        nu_hat = [1 / M for m in range(M)]\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            \n",
    "            source_data = source_data_list[index][i]\n",
    "            target_data = target_data_list[index][i]\n",
    "            \n",
    "            X = []\n",
    "            Y = []\n",
    "            \n",
    "            for m in range(M):\n",
    "                \n",
    "                n_m = int((N / epochs) * (np.abs([1 / M for m in range(M)]) / np.linalg.norm([1 / M for m in range(M)], 1))[m])\n",
    "                \n",
    "                X_temp = np.zeros((d, n_m))\n",
    "                Y_temp = np.zeros(n_m)\n",
    "                \n",
    "                for num in range(n_m):\n",
    "                    \n",
    "                    X_temp[:, num] = source_data[T][m][num]\n",
    "                    Y_temp[num] = source_data[T][m][num].dot(Theta_star[T][:, m]) + noise[T][i][m][num]\n",
    "                    \n",
    "                X.append(X_temp)\n",
    "                Y.append(Y_temp)\n",
    "                \n",
    "            if i == 0:\n",
    "                \n",
    "                B_hat, W_hat, eta, error_list4 = AltGD_Min_1(X, Y, C[index], M, d, k, Theta_star[T], B_star[T], gd_iterations[index])\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                B_hat, W_hat = AltGD_Min_2(X, Y, M, d, k, B_hat, eta, gd_iterations[index] + (i - 1) * increase_gd_iteration[index])\n",
    "                \n",
    "            Theta_hat = B_hat.dot(W_hat)\n",
    "            error = np.linalg.norm(Theta_star[T] - Theta_hat, 'fro') / np.linalg.norm(Theta_star[T], 'fro')\n",
    "            \n",
    "            X_target = np.zeros((num_target_sample, d))\n",
    "            Y_target = np.zeros(num_target_sample)\n",
    "            \n",
    "            for num in range(num_target_sample):\n",
    "                \n",
    "                X_target[num, :] = target_data[T][num]\n",
    "                Y_target[num] = target_data[T][num].dot(Theta_target_star[T]) + noise[T][i][M][num]\n",
    "                \n",
    "            w_hat_target = np.linalg.pinv(X_target.dot(B_hat)).dot(Y_target)\n",
    "            nu_hat = W_hat.T.dot(np.linalg.pinv(np.dot(W_hat, W_hat.T))).dot(w_hat_target)\n",
    "            nu_error = np.linalg.norm(nu_hat - np.linalg.pinv(W_star[T]).dot(W_target_star[T])) / np.linalg.norm(nu)\n",
    "            \n",
    "            term1 = X_target.dot(B_hat).dot(w_hat_target)\n",
    "            term2 = X_target.dot(Theta_target_star[T])\n",
    "            ER = np.sum((term1 - term2) ** 2) / num_target_sample\n",
    "            \n",
    "            ER_4.append(ER)\n",
    "            # print('M: {} epoch: {} error: {} nu_error: {}:'.format(M, i, error, nu_error))\n",
    "            \n",
    "        ER_list4.append((T, M, ER_4))\n",
    "        gd_error_list4.append((T, M, error_list4))\n",
    "        \n",
    "end = time.time()\n",
    "print('Finished! The total time we use is: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97df459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collins Algorithm\n",
    "start = time.time()\n",
    "\n",
    "for T in range(trials):\n",
    "    \n",
    "    print('Trial:', T)\n",
    "    \n",
    "    for index, M in enumerate(M_list):\n",
    "        \n",
    "        B_star = B_star_list[index]\n",
    "        W_star = W_star_list[index]\n",
    "        Theta_star = Theta_star_list[index]\n",
    "        W_target_star = W_target_star_list[index]\n",
    "        Theta_target_star = Theta_target_star_list[index]\n",
    "        \n",
    "        ER_5 = []\n",
    "        nu_hat = [1 / M for m in range(M)]\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            \n",
    "            source_data = source_data_list[index][i]\n",
    "            target_data = target_data_list[index][i]\n",
    "            \n",
    "            X = []\n",
    "            Y = []\n",
    "            \n",
    "            # new\n",
    "            index_m = []\n",
    "            \n",
    "            for m in range(M):\n",
    "                \n",
    "                n_m = int((N / epochs) * (np.abs(nu_hat) / np.linalg.norm(nu_hat, 1))[m])\n",
    "                \n",
    "                # new\n",
    "                if n_m == 0:\n",
    "                    \n",
    "                    M = M - 1\n",
    "                    index_m.append(m)\n",
    "                    \n",
    "                    continue\n",
    "                    \n",
    "                X_temp = np.zeros((d, n_m))\n",
    "                Y_temp = np.zeros(n_m)\n",
    "                \n",
    "                for num in range(n_m):\n",
    "                    \n",
    "                    X_temp[:, num] = source_data[T][m][num]\n",
    "                    Y_temp[num] = source_data[T][m][num].dot(Theta_star[T][:, m]) + noise[T][i][m][num]\n",
    "                    \n",
    "                X.append(X_temp)\n",
    "                Y.append(Y_temp)\n",
    "                \n",
    "            # new\n",
    "            if len(index_m) > 0:\n",
    "                \n",
    "                W_hat_m = W_hat[:, index_m]\n",
    "                \n",
    "            if i == 0:\n",
    "                \n",
    "                B_hat, W_hat, error_list5 = AltGD_Min_Collins1(X, Y, M, d, k, Theta_star[T], B_star[T], gd_iterations[index])\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                B_hat, W_hat = AltGD_Min_Collins2(X, Y, M, d, k, B_hat, gd_iterations[index] + (i - 1) * increase_gd_iteration[index])\n",
    "                \n",
    "            # new\n",
    "            if len(index_m) > 0:\n",
    "                \n",
    "                j = 0\n",
    "                W_temp = np.zeros((k, M + len(index_m)))\n",
    "                \n",
    "                for v in range(M + len(index_m)):\n",
    "                    \n",
    "                    if v in index_m:\n",
    "                        \n",
    "                        continue\n",
    "                        \n",
    "                    W_temp[:, v] = W_hat[:, j]\n",
    "                    j += 1\n",
    "                    \n",
    "                for idx, column in zip(index_m, W_hat_m.T):\n",
    "                    \n",
    "                    W_temp[:, idx] = column\n",
    "                    \n",
    "                W_hat = W_temp\n",
    "                M = M_list[index]\n",
    "                \n",
    "            Theta_hat = B_hat.dot(W_hat)\n",
    "            error = np.linalg.norm(Theta_star[T] - Theta_hat, 'fro') / np.linalg.norm(Theta_star[T], 'fro')\n",
    "            \n",
    "            X_target = np.zeros((num_target_sample, d))\n",
    "            Y_target = np.zeros(num_target_sample)\n",
    "            \n",
    "            for num in range(num_target_sample):\n",
    "                \n",
    "                X_target[num, :] = target_data[T][num]\n",
    "                Y_target[num] = target_data[T][num].dot(Theta_target_star[T]) + noise[T][i][M][num]\n",
    "                \n",
    "            w_hat_target = np.linalg.pinv(X_target.dot(B_hat)).dot(Y_target)\n",
    "            nu_hat = W_hat.T.dot(np.linalg.pinv(np.dot(W_hat, W_hat.T))).dot(w_hat_target)\n",
    "            nu_error = np.linalg.norm(nu_hat - np.linalg.pinv(W_star[T]).dot(W_target_star[T])) / np.linalg.norm(nu)\n",
    "            \n",
    "            term1 = X_target.dot(B_hat).dot(w_hat_target)\n",
    "            term2 = X_target.dot(Theta_target_star[T])\n",
    "            ER = np.sum((term1 - term2) ** 2) / num_target_sample\n",
    "            \n",
    "            ER_5.append(ER)\n",
    "            # print('M: {} epoch: {} error: {} nu_error: {}:'.format(M, i, error, nu_error))\n",
    "            \n",
    "        ER_list5.append((T, M, ER_5))\n",
    "        gd_error_list5.append((T, M, error_list5))\n",
    "        \n",
    "end = time.time()\n",
    "print('Finished! The total time we use is: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c9ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ER_list1.npy', np.array(ER_list1, dtype=object))\n",
    "np.save('ER_list2.npy', np.array(ER_list2, dtype=object))\n",
    "np.save('ER_list3.npy', np.array(ER_list3, dtype=object))\n",
    "np.save('ER_list4.npy', np.array(ER_list4, dtype=object))\n",
    "np.save('ER_list5.npy', np.array(ER_list5, dtype=object))\n",
    "np.save('gd_error_list1.npy', np.array(gd_error_list1, dtype=object))\n",
    "np.save('gd_error_list3.npy', np.array(gd_error_list3, dtype=object))\n",
    "np.save('gd_error_list4.npy', np.array(gd_error_list4, dtype=object))\n",
    "np.save('gd_error_list5.npy', np.array(gd_error_list5, dtype=object))\n",
    "np.save('percentage_error_list2.npy', np.array(percentage_error_list2, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6bfa36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
